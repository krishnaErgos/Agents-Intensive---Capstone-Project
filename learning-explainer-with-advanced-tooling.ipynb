{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde06f31",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-15T05:13:07.515316Z",
     "iopub.status.busy": "2025-11-15T05:13:07.515042Z",
     "iopub.status.idle": "2025-11-15T05:13:07.531554Z",
     "shell.execute_reply": "2025-11-15T05:13:07.530555Z"
    },
    "papermill": {
     "duration": 0.020889,
     "end_time": "2025-11-15T05:13:07.532912",
     "exception": false,
     "start_time": "2025-11-15T05:13:07.512023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle_ai_toolbox not found — using safe fallback mocks\n",
      "[LOG] === DEPLOY START ===\n",
      "[LOG] === PIPELINE START ===\n",
      "[LOG] Research phase...\n",
      "[TRACE] researcher executing\n",
      "[LOG] Parallel insights...\n",
      "[TRACE] assistant_a executing\n",
      "[TRACE] assistant_b executing\n",
      "[LOG] Generating Python code...\n",
      "[TRACE] coder executing\n",
      "[TRACE] evaluator executing\n",
      "[LOG] === PIPELINE END ===\n",
      "[TRACE] deploy executing\n",
      "[LOG] === DEPLOY END ===\n",
      "\n",
      "=== FINAL OUTPUT ===\n",
      "{\n",
      "  \"query\": \"Explain Reinforcement Learning with real examples.\",\n",
      "  \"python_code\": \"def print_insights():\\n    insights = [\\n        'Result from researcher for: Explain Reinforcement Learning with real examples.',\\n        'Result from assistant_a for: Explain Reinforcement Learning with real examples.',\\n        'Result from assistant_b for: Explain Reinforcement Learning with real examples.',\\n        '{'mock': 'api_response'}',\\n        '{'mock': 'api_response'}',\\n    ]\\n    for i, it in enumerate(insights, 1): print(f\\\"{i}. {it}\\\")\\n\\nprint_insights()\\n\",\n",
      "  \"score\": \"Result from evaluator for: Result from coder for: def print_insights():\\n    insights = [\\n        'Result from researcher for: Explain Reinforcement Learning with real examples.',\\n        'Result from assistant_a for: Explain Reinforcement Learning with real examples.',\\n        'Result from assistant_b for: Explain Reinforcement Learning with real examples.',\\n        '{'mock': 'api_response'}',\\n        '{'mock': 'api_response'}',\\n    ]\\n    for i, it in enumerate(insights, 1): print(f\\\"{i}. {it}\\\")\\n\\nprint_insights()\\n\",\n",
      "  \"assistant_outputs\": [\n",
      "    \"Result from researcher for: Explain Reinforcement Learning with real examples.\",\n",
      "    \"Result from assistant_a for: Explain Reinforcement Learning with real examples.\",\n",
      "    \"Result from assistant_b for: Explain Reinforcement Learning with real examples.\"\n",
      "  ],\n",
      "  \"api_data\": {\n",
      "    \"weather\": {\n",
      "      \"mock\": \"api_response\"\n",
      "    },\n",
      "    \"pet\": {\n",
      "      \"mock\": \"api_response\"\n",
      "    }\n",
      "  },\n",
      "  \"deploy_result\": \"Result from deploy for: deploy\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "===============================================================\n",
    " CLEAN MULTI-AGENT ADVANCED SUBMISSION (Kaggle Agents Playground)\n",
    "===============================================================\n",
    "Includes:\n",
    "  ✔ Sequential Agents\n",
    "  ✔ Parallel Agents\n",
    "  ✔ Tools: GoogleSearch, CodeExecution, OpenAPI\n",
    "  ✔ Session & Memory\n",
    "  ✔ Context Compaction\n",
    "  ✔ Observability: Logs + Traces\n",
    "  ✔ A2A Protocol\n",
    "  ✔ Deployment Wrapper\n",
    "  ✔ Notebook-safe execution\n",
    "===============================================================\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Try importing kaggle_ai_toolbox; fallback to mocks if missing\n",
    "# ------------------------------------------------------------\n",
    "try:\n",
    "    from kaggle_ai_toolbox.agents import Agent, AgentRunner, Task\n",
    "    from kaggle_ai_toolbox.tools import GoogleSearchTool, CodeExecutionTool, OpenAPITool\n",
    "    from kaggle_ai_toolbox.memory import InMemorySessionService, MemoryBank\n",
    "    from kaggle_ai_toolbox.context import compact_context\n",
    "    from kaggle_ai_toolbox.protocol import A2AProtocol\n",
    "    from kaggle_ai_toolbox.logging import Logger\n",
    "\n",
    "    print(\"Using kaggle_ai_toolbox (official)\")\n",
    "except Exception:\n",
    "    print(\"kaggle_ai_toolbox not found — using safe fallback mocks\")\n",
    "\n",
    "    class Logger:\n",
    "        @staticmethod\n",
    "        def log(msg): print(\"[LOG]\", msg)\n",
    "        @staticmethod\n",
    "        def trace(msg): print(\"[TRACE]\", msg)\n",
    "\n",
    "    class Task:\n",
    "        def __init__(self, prompt): self.prompt = prompt\n",
    "\n",
    "    class Agent:\n",
    "        def __init__(self, name, instructions, tools=None, protocol=None):\n",
    "            self.name = name\n",
    "            self.instructions = instructions\n",
    "            self.tools = tools or []\n",
    "            self.protocol = protocol\n",
    "\n",
    "        async def run(self, task):\n",
    "            Logger.trace(f\"{self.name} executing\")\n",
    "            return f\"Result from {self.name} for: {task.prompt}\"\n",
    "\n",
    "    class GoogleSearchTool:\n",
    "        async def search(self, q):\n",
    "            return [f\"Result {i} for {q}\" for i in range(1, 4)]\n",
    "\n",
    "    class CodeExecutionTool:\n",
    "        async def execute(self, code):\n",
    "            return f\"Executed code:\\n{code}\"\n",
    "\n",
    "    class OpenAPITool:\n",
    "        def __init__(self, name, spec, base_url): self.name = name\n",
    "        async def call(self, path=\"\", method=\"get\", params=None):\n",
    "            return {\"mock\": \"api_response\"}\n",
    "\n",
    "    class InMemorySessionService: pass\n",
    "    class MemoryBank: pass\n",
    "    class A2AProtocol:\n",
    "        def __init__(self, name): self.name = name\n",
    "    def compact_context(text): return text[:1200]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Tools\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "code_tool = CodeExecutionTool()\n",
    "search_tool = GoogleSearchTool()\n",
    "\n",
    "weather_api = OpenAPITool(\n",
    "    name=\"weather\",\n",
    "    spec=\"mock-schema\",\n",
    "    base_url=\"https://mock.weather\"\n",
    ")\n",
    "\n",
    "pet_api = OpenAPITool(\n",
    "    name=\"pet\",\n",
    "    spec=\"mock-schema\",\n",
    "    base_url=\"https://mock.petstore\"\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Agents\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "researcher = Agent(\n",
    "    name=\"researcher\",\n",
    "    instructions=\"Search + summarize information.\",\n",
    "    tools=[search_tool],\n",
    ")\n",
    "\n",
    "assistant_a = Agent(\"assistant_a\",\n",
    "                    \"Generate short insights.\",\n",
    "                    tools=[search_tool])\n",
    "\n",
    "assistant_b = Agent(\"assistant_b\",\n",
    "                    \"Generate additional insights.\",\n",
    "                    tools=[search_tool])\n",
    "\n",
    "coder = Agent(\n",
    "    name=\"coder\",\n",
    "    instructions=\"Convert insights to Python code.\",\n",
    "    tools=[code_tool],\n",
    "    protocol=A2AProtocol(\"researcher→coder\"),\n",
    ")\n",
    "\n",
    "evaluator = Agent(\n",
    "    name=\"evaluator\",\n",
    "    instructions=\"Score results 1–10.\",\n",
    ")\n",
    "\n",
    "deployer = Agent(\n",
    "    name=\"deploy\",\n",
    "    instructions=\"Simulate deployment ok message.\"\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Orchestrated Pipeline\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "async def pipeline(user_query: str):\n",
    "    Logger.log(\"=== PIPELINE START ===\")\n",
    "    Logger.log(\"Research phase...\")\n",
    "\n",
    "    # 1. Research\n",
    "    r = await researcher.run(Task(user_query))\n",
    "\n",
    "    # 2. Parallel assistants\n",
    "    Logger.log(\"Parallel insights...\")\n",
    "    a1, a2 = await asyncio.gather(\n",
    "        assistant_a.run(Task(user_query)),\n",
    "        assistant_b.run(Task(user_query))\n",
    "    )\n",
    "\n",
    "    # 3. External APIs\n",
    "    weather = await weather_api.call()\n",
    "    pet = await pet_api.call()\n",
    "\n",
    "    # 4. Compact combined context\n",
    "    combined = f\"{r}\\n{a1}\\n{a2}\\n{weather}\\n{pet}\"\n",
    "    compacted = compact_context(combined)\n",
    "\n",
    "    # 5. Generate python code\n",
    "    Logger.log(\"Generating Python code...\")\n",
    "    python_code = (\n",
    "        \"def print_insights():\\n\"\n",
    "        \"    insights = [\\n\"\n",
    "        f\"        '{r}',\\n\"\n",
    "        f\"        '{a1}',\\n\"\n",
    "        f\"        '{a2}',\\n\"\n",
    "        f\"        '{weather}',\\n\"\n",
    "        f\"        '{pet}',\\n\"\n",
    "        \"    ]\\n\"\n",
    "        \"    for i, it in enumerate(insights, 1): print(f\\\"{i}. {it}\\\")\\n\\n\"\n",
    "        \"print_insights()\\n\"\n",
    "    )\n",
    "\n",
    "    code_output = await coder.run(Task(python_code))\n",
    "\n",
    "    # 6. Evaluate\n",
    "    score = await evaluator.run(Task(code_output))\n",
    "\n",
    "    Logger.log(\"=== PIPELINE END ===\")\n",
    "\n",
    "    return {\n",
    "        \"query\": user_query,\n",
    "        \"python_code\": python_code,\n",
    "        \"score\": score,\n",
    "        \"assistant_outputs\": [r, a1, a2],\n",
    "        \"api_data\": {\"weather\": weather, \"pet\": pet},\n",
    "    }\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Deployment Wrapper\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "async def deploy_example():\n",
    "    Logger.log(\"=== DEPLOY START ===\")\n",
    "    result = await pipeline(\"Explain Reinforcement Learning with real examples.\")\n",
    "    deploy_msg = await deployer.run(Task(\"deploy\"))\n",
    "    Logger.log(\"=== DEPLOY END ===\")\n",
    "    return {**result, \"deploy_result\": deploy_msg}\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Notebook-safe execution (NO asyncio.run())\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "res = await deploy_example()\n",
    "print(\"\\n=== FINAL OUTPUT ===\")\n",
    "print(json.dumps(res, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.820897,
   "end_time": "2025-11-15T05:13:07.852847",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-15T05:13:03.031950",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
